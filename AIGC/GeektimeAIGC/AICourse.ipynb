{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI 大模型之美"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基础知识篇：探索大型语言模型的能力"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OpenAI API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 创建 OpenAI API Key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 搭建本地的 Jupyter Labs 开发环境"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 通过 Colab 使用 JupyterLab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 体验并测试 OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "COMPLETION_MODEL = \"text-davinci-003\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "Consideration product : 工厂现货PVC充气青蛙夜市地摊热卖充气玩具发光蛙儿童水上玩具\n",
    "\n",
    "1. Compose human readable product title used on Amazon in english within 20 words.\n",
    "2. Write 5 selling points for the products in Amazon.\n",
    "3. Evaluate a price range for this product in U.S.\n",
    "\n",
    "Output the result in json format with three properties called title, selling_points and price_range\n",
    "\"\"\"\n",
    "\n",
    "def get_response(prompt):\n",
    "    completions = openai.Completion.create (\n",
    "        engine=COMPLETION_MODEL,\n",
    "        prompt=prompt,\n",
    "        max_tokens=512,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0.0,        \n",
    "    )\n",
    "    message = completions.choices[0].text\n",
    "    return message\n",
    "\n",
    "print(get_response(prompt)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Man Utd must win trophies, says Ten Hag ahead of League Cup final\n",
    "\n",
    "请将上面这句话的人名提取出来，并用json的方式展示出来\n",
    "\"\"\"\n",
    "\n",
    "print(get_response(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 如何利用大语言模型做情感分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 传统的二分类方法：朴素贝叶斯与逻辑回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 传统方法的挑战：特征工程与模型调参"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 大语言模型：20 行代码的情感分析解决方案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from openai.embeddings_utils import cosine_similarity, get_embedding\n",
    "\n",
    "# 获取访问open ai的密钥\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "# 选择使用最小的ada模型\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "\n",
    "# 获取\"好评\"和\"差评\"的\n",
    "positive_review = get_embedding(\"好评\")\n",
    "negative_review = get_embedding(\"差评\")\n",
    "\n",
    "positive_example = get_embedding(\"买的银色版真的很好看，一天就到了，晚上就开始拿起来完系统很丝滑流畅，做工扎实，手感细腻，很精致哦苹果一如既往的好品质\")\n",
    "negative_example = get_embedding(\"降价厉害，保价不合理，不推荐\")\n",
    "\n",
    "def get_score(sample_embedding):\n",
    "  return cosine_similarity(sample_embedding, positive_review) - cosine_similarity(sample_embedding, negative_review)\n",
    "\n",
    "positive_score = get_score(positive_example)\n",
    "negative_score = get_score(negative_example)\n",
    "\n",
    "print(\"好评例子的评分 : %f\" % (positive_score))\n",
    "print(\"差评例子的评分 : %f\" % (negative_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "good_restraurant = get_embedding(\"这家餐馆太好吃了，一点都不糟糕\")\n",
    "bad_restraurant = get_embedding(\"这家餐馆太糟糕了，一点都不好吃\")\n",
    "\n",
    "good_score = get_score(good_restraurant)\n",
    "bad_score = get_score(bad_restraurant)\n",
    "print(\"好评餐馆的评分 : %f\" % (good_score))\n",
    "print(\"差评餐馆的评分 : %f\" % (bad_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 更大的数据集上的真实案例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "datafile_path = \"data/fine_food_reviews_with_embeddings_1k.csv\"\n",
    "\n",
    "df = pd.read_csv(datafile_path)\n",
    "df[\"embedding\"] = df.embedding.apply(eval).apply(np.array)\n",
    "\n",
    "# convert 5-star rating to binary sentiment\n",
    "df = df[df.Score != 3]\n",
    "df[\"sentiment\"] = df.Score.replace({1: \"negative\", 2: \"negative\", 4: \"positive\", 5: \"positive\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "\n",
    "def evaluate_embeddings_approach(\n",
    "    labels = ['negative', 'positive'], \n",
    "    model = EMBEDDING_MODEL,\n",
    "):\n",
    "    label_embeddings = [get_embedding(label, engine=model) for label in labels]\n",
    "\n",
    "    def label_score(review_embedding, label_embeddings):\n",
    "        return cosine_similarity(review_embedding, label_embeddings[1]) - cosine_similarity(review_embedding, label_embeddings[0])\n",
    "\n",
    "    probas = df[\"embedding\"].apply(lambda x: label_score(x, label_embeddings))\n",
    "    preds = probas.apply(lambda x: 'positive' if x>0 else 'negative')\n",
    "\n",
    "    report = classification_report(df.sentiment, preds)\n",
    "    print(report)\n",
    "\n",
    "    display = PrecisionRecallDisplay.from_predictions(df.sentiment, probas, pos_label='positive')\n",
    "    _ = display.ax_.set_title(\"2-class Precision-Recall curve\")\n",
    "\n",
    "evaluate_embeddings_approach(labels=['An Amazon review with a negative sentiment.', 'An Amazon review with a positive sentiment.'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 巧用提示语说说话就能做个聊天机器人"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* AI 客服"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "COMPLETION_MODEL = \"text-davinci-003\"\n",
    "\n",
    "prompt = '请你用朋友的语气回复给到客户，并称他为“亲”，他的订单已经发货在路上了，预计在3天之内会送达，订单号2021AEDG，我们很抱歉因为天气的原因物流时间比原来长，感谢他选购我们的商品。'\n",
    "\n",
    "def get_response(prompt, temperature = 1.0):\n",
    "    completions = openai.Completion.create (\n",
    "        engine=COMPLETION_MODEL,\n",
    "        prompt=prompt,\n",
    "        max_tokens=1024,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    message = completions.choices[0].text\n",
    "    return message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* AI 聊天机器人"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "def ask_gpt3(prompt):\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=512,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0.5,\n",
    "    )\n",
    "\n",
    "    message = response.choices[0].text.strip()\n",
    "    return message\n",
    "\n",
    "print(\"你好，我是一个聊天机器人，请你提出你的问题吧?\")\n",
    "\n",
    "questions = []\n",
    "answers = []\n",
    "\n",
    "def generate_prompt(prompt, questions, answers):\n",
    "    num = len(answers)\n",
    "    for i in range(num):\n",
    "        prompt += \"\\n Q : \" + questions[i]\n",
    "        prompt += \"\\n A : \" + answers[i]\n",
    "    prompt += \"\\n Q : \" + questions[num] + \"\\n A : \"        \n",
    "    return prompt\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"> \")\n",
    "    questions.append(user_input)\n",
    "    if user_input.lower() in [\"bye\", \"goodbye\", \"exit\"]:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "    \n",
    "    prompt = generate_prompt(\"\", questions, answers)\n",
    "\n",
    "    answer = ask_gpt3(prompt)\n",
    "    print(answer)\n",
    "    answers.append(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 让 AI 帮我解决情感分析问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "prompts = \"\"\"判断一下用户的评论情感上是正面的还是负面的\n",
    "评论：买的银色版真的很好看，一天就到了，晚上就开始拿起来完系统很丝滑流畅，做工扎实，手感细腻，很精致哦苹果一如既往的好品质\n",
    "情感：正面\n",
    "\n",
    "评论：随意降价，不予价保，服务态度差\n",
    "情感：负面\n",
    "\"\"\"\n",
    "\n",
    "good_case = prompts + \"\"\"\n",
    "评论：外形外观：苹果审美一直很好，金色非常漂亮\n",
    "拍照效果：14pro升级的4800万像素真的是没的说，太好了，\n",
    "运行速度：苹果的反应速度好，用上三五年也不会卡顿的，之前的7P用到现在也不卡\n",
    "其他特色：14pro的磨砂金真的太好看了，不太高调，也不至于没有特点，非常耐看，很好的\n",
    "情感：\n",
    "\"\"\"\n",
    "\n",
    "print(get_response(good_case))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "bad_case = prompts + \"\"\"\n",
    "评论：信号不好电池也不耐电不推荐购买\n",
    "情感\n",
    "\"\"\"\n",
    "\n",
    "print(get_response(bad_case))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 新时代模型性能大比拼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Fasttext 效果测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "# Load the FastText pre-trained model\n",
    "model = gensim.models.fasttext.load_facebook_model('cc.en.300.bin')\n",
    "\n",
    "def get_fasttext_vector(line):\n",
    "    vec = np.zeros(300) # Initialize an empty 300-dimensional vector\n",
    "    for word in line.split():\n",
    "        vec += model.wv[word]\n",
    "    vec /= len(line.split()) # Take the average over all words in the line\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "positive_text = \"\"\"Wanted to save some to bring to my Chicago family but my North Carolina family ate all 4 boxes before I could pack. These are excellent...could serve to anyone\"\"\"\n",
    "negative_text = \"\"\"First, these should be called Mac - Coconut bars, as Coconut is the #2 ingredient and Mango is #3.  Second, lots of people don't like coconut.  I happen to be allergic to it.  Word to Amazon that if you want happy customers to make things like this more prominent.  Thanks.\"\"\"\n",
    "\n",
    "positive_example_in_fasttext = get_fasttext_vector(positive_text)\n",
    "negative_example_in_fasttext = get_fasttext_vector(negative_text)\n",
    "\n",
    "positive_review_in_fasttext = get_fasttext_vector(\"An Amazon review with a positive sentiment.\")\n",
    "negative_review_in_fasttext = get_fasttext_vector('An Amazon review with a negative sentiment.')\n",
    "\n",
    "from openai.embeddings_utils import cosine_similarity\n",
    "\n",
    "def get_fasttext_score(sample_embedding):\n",
    "  return cosine_similarity(sample_embedding, positive_review_in_fasttext) - cosine_similarity(sample_embedding, negative_review_in_fasttext)\n",
    "\n",
    "positive_score = get_fasttext_score(positive_example_in_fasttext)\n",
    "negative_score = get_fasttext_score(negative_example_in_fasttext)\n",
    "\n",
    "print(\"Fasttext好评例子的评分 : %f\" % (positive_score))\n",
    "print(\"Fasttext差评例子的评分 : %f\" % (negative_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* T5 效果测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5Model\n",
    "import torch\n",
    "\n",
    "# load the T5 tokenizer and model\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small', model_max_length=512)\n",
    "model = T5Model.from_pretrained('t5-small')\n",
    "\n",
    "# set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# encode the input sentence\n",
    "def get_t5_vector(line):\n",
    "    input_ids = tokenizer.encode(line, return_tensors='pt', max_length=512, truncation=True)\n",
    "    # generate the vector representation\n",
    "    with torch.no_grad():\n",
    "        outputs = model.encoder(input_ids=input_ids)\n",
    "        vector = outputs.last_hidden_state.mean(dim=1)\n",
    "    return vector[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "positive_review_in_t5 = get_t5_vector(\"An Amazon review with a positive sentiment.\")\n",
    "negative_review_in_t5 = get_t5_vector('An Amazon review with a negative sentiment.')\n",
    "\n",
    "def test_t5():\n",
    "  positive_example_in_t5 = get_t5_vector(positive_text)\n",
    "  negative_example_in_t5 = get_t5_vector(negative_text)\n",
    "\n",
    "  def get_t5_score(sample_embedding):\n",
    "    return cosine_similarity(sample_embedding, positive_review_in_t5) - cosine_similarity(sample_embedding, negative_review_in_t5)\n",
    "\n",
    "  positive_score = get_t5_score(positive_example_in_t5)\n",
    "  negative_score = get_t5_score(negative_example_in_t5)\n",
    "\n",
    "  print(\"T5好评例子的评分 : %f\" % (positive_score))\n",
    "  print(\"T5差评例子的评分 : %f\" % (negative_score))\n",
    "\n",
    "test_t5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained('t5-base', model_max_length=512)\n",
    "model = T5Model.from_pretrained('t5-base')\n",
    "\n",
    "# set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# encode the input sentence\n",
    "def get_t5_vector(line):\n",
    "    input_ids = tokenizer.encode(line, return_tensors='pt', max_length=512, truncation=True)\n",
    "    # generate the vector representation\n",
    "    with torch.no_grad():\n",
    "        outputs = model.encoder(input_ids=input_ids)\n",
    "        vector = outputs.last_hidden_state.mean(dim=1)\n",
    "    return vector[0]\n",
    "\n",
    "positive_review_in_t5 = get_t5_vector(\"An Amazon review with a positive sentiment.\")\n",
    "negative_review_in_t5 = get_t5_vector('An Amazon review with a negative sentiment.')\n",
    "\n",
    "test_t5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "datafile_path = \"data/fine_food_reviews_with_embeddings_1k.csv\"\n",
    "\n",
    "df = pd.read_csv(datafile_path)\n",
    "\n",
    "df[\"t5_embedding\"] = df.Text.apply(get_t5_vector)\n",
    "# convert 5-star rating to binary sentiment\n",
    "df = df[df.Score != 3]\n",
    "df[\"sentiment\"] = df.Score.replace({1: \"negative\", 2: \"negative\", 4: \"positive\", 5: \"positive\"})\n",
    "\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "def evaluate_embeddings_approach():\n",
    "    def label_score(review_embedding):\n",
    "        return cosine_similarity(review_embedding, positive_review_in_t5) - cosine_similarity(review_embedding, negative_review_in_t5)\n",
    "\n",
    "    probas = df[\"t5_embedding\"].apply(lambda x: label_score(x))\n",
    "    preds = probas.apply(lambda x: 'positive' if x>0 else 'negative')\n",
    "\n",
    "    report = classification_report(df.sentiment, preds)\n",
    "    print(report)\n",
    "\n",
    "    display = PrecisionRecallDisplay.from_predictions(df.sentiment, probas, pos_label='positive')\n",
    "    _ = display.ax_.set_title(\"2-class Precision-Recall curve\")\n",
    "\n",
    "evaluate_embeddings_approach()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 善用Embedding 来给文本分分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 利用 Embedding 训练机器学习模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tiktoken\n",
    "import openai\n",
    "import os\n",
    "\n",
    "from openai.embeddings_utils import get_embedding, get_embeddings\n",
    "\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "# embedding model parameters\n",
    "embedding_model = \"text-embedding-ada-002\"\n",
    "embedding_encoding = \"cl100k_base\"  # this the encoding for text-embedding-ada-002\n",
    "max_tokens = 8000  # the maximum for text-embedding-ada-002 is 8191\n",
    "\n",
    "# import data/toutiao_cat_data.txt as a pandas dataframe\n",
    "df = pd.read_csv('data/toutiao_cat_data.txt', sep='_!_', names=['id', 'code', 'category', 'title', 'keywords'])\n",
    "df = df.fillna(\"\")\n",
    "df[\"combined\"] = (\n",
    "    \"标题: \" + df.title.str.strip() + \"; 关键字: \" + df.keywords.str.strip()\n",
    ")\n",
    "\n",
    "print(\"Lines of text before filtering: \", len(df))\n",
    "\n",
    "encoding = tiktoken.get_encoding(embedding_encoding)\n",
    "# omit reviews that are too long to embed\n",
    "df[\"n_tokens\"] = df.combined.apply(lambda x: len(encoding.encode(x)))\n",
    "df = df[df.n_tokens <= max_tokens]\n",
    "\n",
    "print(\"Lines of text after filtering: \", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# randomly sample 1k rows\n",
    "df_1k = df.sample(1000, random_state=42)\n",
    "\n",
    "df_1k[\"embedding\"] = df_1k.combined.apply(lambda x : get_embedding(x, engine=embedding_model))\n",
    "df_1k.to_csv(\"data/toutiao_cat_data_10k_with_embeddings.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import backoff\n",
    "\n",
    "@backoff.on_exception(backoff.expo, openai.error.RateLimitError)\n",
    "def get_embedding_with_backoff(**kwargs):\n",
    "    return get_embedding(**kwargs)\n",
    "\n",
    "# randomly sample 10k rows\n",
    "df_10k = df.sample(10000, random_state=42)\n",
    "\n",
    "df_10k[\"embedding\"] = df_10k.combined.apply(lambda x : get_embedding_with_backoff(text=x, engine=embedding_model))\n",
    "df_10k.to_csv(\"data/toutiao_cat_data_10k_with_embeddings.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import backoff\n",
    "from openai.embeddings_utils import get_embeddings\n",
    "\n",
    "batch_size = 1000\n",
    "\n",
    "@backoff.on_exception(backoff.expo, openai.error.RateLimitError)\n",
    "def get_embeddings_with_backoff(prompts, engine):\n",
    "    embeddings = []\n",
    "    for i in range(0, len(prompts), batch_size):\n",
    "        batch = prompts[i:i+batch_size]\n",
    "        embeddings += get_embeddings(list_of_text=batch, engine=engine)\n",
    "    return embeddings\n",
    "\n",
    "# randomly sample 10k rows\n",
    "df_all = df\n",
    "# group prompts into batches of 100\n",
    "prompts = df_all.combined.tolist()\n",
    "prompt_batches = [prompts[i:i+batch_size] for i in range(0, len(prompts), batch_size)]\n",
    "\n",
    "embeddings = []\n",
    "for batch in prompt_batches:\n",
    "    batch_embeddings = get_embeddings_with_backoff(prompts=batch, engine=embedding_model)\n",
    "    embeddings += batch_embeddings\n",
    "\n",
    "df_all[\"embedding\"] = embeddings\n",
    "df_all.to_parquet(\"data/toutiao_cat_data_all_with_embeddings.parquet\", index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 看看效果怎么样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "training_data = pd.read_parquet(\"data/toutiao_cat_data_all_with_embeddings.parquet\")\n",
    "training_data.head()\n",
    "\n",
    "df =  training_data.sample(50000, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    list(df.embedding.values), df.category, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=300)\n",
    "clf.fit(X_train, y_train)\n",
    "preds = clf.predict(X_test)\n",
    "probas = clf.predict_proba(X_test)\n",
    "\n",
    "report = classification_report(y_test, preds)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "df =  training_data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    list(df.embedding.values), df.category, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "preds = clf.predict(X_test)\n",
    "probas = clf.predict_proba(X_test)\n",
    "\n",
    "report = classification_report(y_test, preds)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实战提高篇（一）：利用NLP技术完成高级任务"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实战提高篇（二）：大型语音与图像模型的应用"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
